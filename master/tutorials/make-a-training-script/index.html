<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=../../advanced-tutorials/fastapi/ rel=prev><link href=../quick-examples/ rel=next><link rel=icon href=../../assets/logo/edsnlp.svg><meta name=generator content="mkdocs-1.5.3, mkdocs-material-9.2.8"><title>Making a training script - EDS-NLP</title><link rel=stylesheet href=../../assets/stylesheets/main.046329b4.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.85d0ee34.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../assets/_mkdocstrings.css><link rel=stylesheet href=../../assets/stylesheets/extra.css><link rel=stylesheet href=../../assets/stylesheets/cards.css><link rel=stylesheet href=../../assets/termynal/termynal.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href="#making-a-training-script" class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href="../.." title=EDS-NLP class="md-header__button md-logo" aria-label=EDS-NLP data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> EDS-NLP </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Making a training script </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> </form> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href="https://github.com/aphp/edsnlp" title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> aphp/edsnlp </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href="../.." title=EDS-NLP class="md-nav__button md-logo" aria-label=EDS-NLP data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg> </a> EDS-NLP </label> <div class=md-nav__source> <a href="https://github.com/aphp/edsnlp" title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> aphp/edsnlp </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href="../.." class=md-nav__link> <span class=md-ellipsis> Getting started </span> </a> </li> <li class=md-nav__item> <a href="https://aphp.github.io/edsnlp/demo" target=_blank class=md-nav__link> <span class=md-ellipsis> Demo </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <div class="md-nav__link md-nav__container"> <a href="../" class="md-nav__link "> <span class=md-ellipsis> Tutorials </span> </a> <label class="md-nav__link " for=__nav_3> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href="../" class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href="../spacy101/" class=md-nav__link> <span class=md-ellipsis> SpaCy representations </span> </a> </li> <li class=md-nav__item> <a href="../matching-a-terminology/" class=md-nav__link> <span class=md-ellipsis> Matching a terminology </span> </a> </li> <li class=md-nav__item> <a href="../qualifying-entities/" class=md-nav__link> <span class=md-ellipsis> Qualifying entities </span> </a> </li> <li class=md-nav__item> <a href="../detecting-dates/" class=md-nav__link> <span class=md-ellipsis> Detecting dates </span> </a> </li> <li class=md-nav__item> <a href="../multiple-texts/" class=md-nav__link> <span class=md-ellipsis> Processing multiple texts </span> </a> </li> <li class=md-nav__item> <a href="../reason/" class=md-nav__link> <span class=md-ellipsis> Detecting Reason of Hospitalisation </span> </a> </li> <li class=md-nav__item> <a href="../endlines/" class=md-nav__link> <span class=md-ellipsis> Detecting end-of-lines </span> </a> </li> <li class=md-nav__item> <a href="../aggregating-results/" class=md-nav__link> <span class=md-ellipsis> Aggregating results </span> </a> </li> <li class=md-nav__item> <a href="../../advanced-tutorials/fastapi/" class=md-nav__link> <span class=md-ellipsis> Deploying as an API </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Making a training script </span> <span class="md-nav__icon md-icon"></span> </label> <a href="./" class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Making a training script </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href="#step-by-step-walkthrough" class=md-nav__link> Step-by-step walkthrough </a> <nav class=md-nav aria-label="Step-by-step walkthrough"> <ul class=md-nav__list> <li class=md-nav__item> <a href="#1-defining-the-model" class=md-nav__link> 1. Defining the model </a> </li> <li class=md-nav__item> <a href="#2-adapting-a-dataset" class=md-nav__link> 2. Adapting a dataset </a> </li> <li class=md-nav__item> <a href="#3-loading-the-data" class=md-nav__link> 3. Loading the data </a> </li> <li class=md-nav__item> <a href="#4-complete-the-initialization-with-the-training-data" class=md-nav__link> 4. Complete the initialization with the training data </a> </li> <li class=md-nav__item> <a href="#5-preprocessing-the-data" class=md-nav__link> 5. Preprocessing the data </a> </li> <li class=md-nav__item> <a href="#6-looping-through-the-training-data" class=md-nav__link> 6. Looping through the training data </a> </li> <li class=md-nav__item> <a href="#7-optimizing-the-weights" class=md-nav__link> 7. Optimizing the weights </a> </li> <li class=md-nav__item> <a href="#8-evaluating-the-model" class=md-nav__link> 8. Evaluating the model </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href="#full-example" class=md-nav__link> Full example </a> </li> <li class=md-nav__item> <a href="#configuration" class=md-nav__link> Configuration </a> </li> <li class=md-nav__item> <a href="#going-further" class=md-nav__link> Going further </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href="../quick-examples/" class=md-nav__link> <span class=md-ellipsis> Display single text outputs </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href="../../pipes/" class=md-nav__link> <span class=md-ellipsis> Pipes </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href="../../tokenizers/" class=md-nav__link> <span class=md-ellipsis> Tokenizers </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href="../../data/" class=md-nav__link> <span class=md-ellipsis> Data Connectors </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href="../../concepts/pipeline/" class=md-nav__link> <span class=md-ellipsis> Concepts </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href="../../utilities/" class=md-nav__link> <span class=md-ellipsis> Utilities </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href="../../reference/edsnlp/" class=md-nav__link> <span class=md-ellipsis> Code Reference </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href="../../contributing/" class=md-nav__link> <span class=md-ellipsis> Contributing to EDS-NLP </span> </a> </li> <li class=md-nav__item> <a href="../../changelog/" class=md-nav__link> <span class=md-ellipsis> Changelog </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href="#step-by-step-walkthrough" class=md-nav__link> Step-by-step walkthrough </a> <nav class=md-nav aria-label="Step-by-step walkthrough"> <ul class=md-nav__list> <li class=md-nav__item> <a href="#1-defining-the-model" class=md-nav__link> 1. Defining the model </a> </li> <li class=md-nav__item> <a href="#2-adapting-a-dataset" class=md-nav__link> 2. Adapting a dataset </a> </li> <li class=md-nav__item> <a href="#3-loading-the-data" class=md-nav__link> 3. Loading the data </a> </li> <li class=md-nav__item> <a href="#4-complete-the-initialization-with-the-training-data" class=md-nav__link> 4. Complete the initialization with the training data </a> </li> <li class=md-nav__item> <a href="#5-preprocessing-the-data" class=md-nav__link> 5. Preprocessing the data </a> </li> <li class=md-nav__item> <a href="#6-looping-through-the-training-data" class=md-nav__link> 6. Looping through the training data </a> </li> <li class=md-nav__item> <a href="#7-optimizing-the-weights" class=md-nav__link> 7. Optimizing the weights </a> </li> <li class=md-nav__item> <a href="#8-evaluating-the-model" class=md-nav__link> 8. Evaluating the model </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href="#full-example" class=md-nav__link> Full example </a> </li> <li class=md-nav__item> <a href="#configuration" class=md-nav__link> Configuration </a> </li> <li class=md-nav__item> <a href="#going-further" class=md-nav__link> Going further </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=making-a-training-script>Making a training script</h1> <p>In this tutorial, we'll see how we can train a deep learning model with EDS-NLP. We will implement a script to train a named-entity recognition (NER) model.</p> <h2 id=step-by-step-walkthrough>Step-by-step walkthrough</h2> <p>Training a supervised deep-learning model consists in feeding batches of annotated samples taken from a training corpus to a model and optimizing its parameters of the model to decrease its prediction error. The process of training a pipeline with EDS-NLP is structured as follows:</p> <h3 id=1-defining-the-model>1. Defining the model</h3> <p>We first start by seeding the random states and instantiating a new trainable pipeline. The model described here computes text embeddings with a pre-trained transformer followed by a CNN, and performs the NER prediction task using a Conditional Random Field (CRF) token classifier. To compose deep-learning modules, we nest them in a dictionary : each new dictionary will instantiate a new module, and the <code>@factory</code> key will be used to select the class of the module.</p> <div class="annotate highlight"><pre><span></span><code><span class=kn>import</span> <span class=nn>edsnlp</span>
<span class=kn>from</span> <span class=nn>confit.utils.random</span> <span class=kn>import</span> <span class=n>set_seed</span>

<span class=n>set_seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=n>nlp</span> <span class=o>=</span> <span class=n>edsnlp</span><span class=o>.</span><span class=n>blank</span><span class=p>(</span><span class=s2>&quot;eds&quot;</span><span class=p>)</span>
<span class=n>nlp</span><span class=o>.</span><span class=n>add_pipe</span><span class=p>(</span>
    <span class=s2>&quot;<a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a>&quot;</span><span class=p>,</span>  <span class=c1># (1)</span>
    <span class=n>name</span><span class=o>=</span><span class=s2>&quot;ner&quot;</span><span class=p>,</span>
    <span class=n>config</span><span class=o>=</span><span class=p>{</span>
        <span class=s2>&quot;mode&quot;</span><span class=p>:</span> <span class=s2>&quot;joint&quot;</span><span class=p>,</span>  <span class=c1># (2)</span>
        <span class=s2>&quot;target_span_getter&quot;</span><span class=p>:</span> <span class=s2>&quot;ml-ner&quot;</span><span class=p>,</span> <span class=c1># (3)</span>
        <span class=s2>&quot;embedding&quot;</span><span class=p>:</span> <span class=p>{</span>
            <span class=s2>&quot;@factory&quot;</span><span class=p>:</span> <span class=s2>&quot;<a href="../../pipes/trainable/embeddings/text_cnn/#edsnlp.pipes.trainable.embeddings.text_cnn.factory.create_component">eds.text_cnn</a>&quot;</span><span class=p>,</span>  <span class=c1># (4)</span>
            <span class=s2>&quot;kernel_sizes&quot;</span><span class=p>:</span> <span class=p>[</span><span class=mi>3</span><span class=p>],</span>
            <span class=s2>&quot;embedding&quot;</span><span class=p>:</span> <span class=p>{</span>
                <span class=s2>&quot;@factory&quot;</span><span class=p>:</span> <span class=s2>&quot;<a href="../../pipes/trainable/embeddings/transformer/#edsnlp.pipes.trainable.embeddings.transformer.factory.create_component">eds.transformer</a>&quot;</span><span class=p>,</span>  <span class=c1># (5)</span>
                <span class=s2>&quot;model&quot;</span><span class=p>:</span> <span class=s2>&quot;prajjwal1/bert-tiny&quot;</span><span class=p>,</span>  <span class=c1># (6)</span>
                <span class=s2>&quot;window&quot;</span><span class=p>:</span> <span class=mi>128</span><span class=p>,</span>
                <span class=s2>&quot;stride&quot;</span><span class=p>:</span> <span class=mi>96</span><span class=p>,</span>
            <span class=p>},</span>
        <span class=p>},</span>
    <span class=p>},</span>
<span class=p>)</span>
</code></pre></div> <ol> <li>We use the <code><a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a></code> NER task module, which classifies word embeddings into NER labels (BIOUL scheme) using a CRF.</li> <li>Each component of the pipeline can be configured with a dictionary, using the parameter described in the component's page.</li> <li>The <code>target_span_getter</code> parameter defines the name of the span group used to train the NER model. We will need to make sure the entities from the training dataset are assigned to this span group (next section).</li> <li>The word embeddings used by the CRF are computed by a CNN, which builds on top of another embedding layer.</li> <li>The base embedding layer is a pretrained transformer, which computes contextualized word embeddings.</li> <li>We chose the <code>prajjwal1/bert-tiny</code> model in this tutorial for testing purposes, but we recommend using a larger model like <code>bert-base-cased</code> or <code>camembert-base</code> (French) for real-world applications.</li> </ol> <h3 id=2-adapting-a-dataset>2. Adapting a dataset</h3> <p>To train a pipeline, we must convert our annotated data into documents that will be either used as training samples or a evaluation samples. This is done by designing a function to convert the dataset into a list of spaCy Doc objects. We will assume the dataset has been annotated using <a href="https://brat.nlplab.org">Brat</a>, but any format can be used.</p> <p>At this step, we might also want to perform data augmentation, filtering, splitting or any other data transformation. Note that this function will be used to load both the training data and the test data.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>pydantic</span> <span class=kn>import</span> <span class=n>DirectoryPath</span>
<span class=kn>import</span> <span class=nn>edsnlp</span>


<span class=nd>@edsnlp</span><span class=o>.</span><span class=n>registry</span><span class=o>.</span><span class=n>adapters</span><span class=o>.</span><span class=n>register</span><span class=p>(</span><span class=s2>&quot;ner_adapter&quot;</span><span class=p>)</span>
<span class=k>def</span> <span class=nf>ner_adapter</span><span class=p>(</span>
    <span class=n>path</span><span class=p>:</span> <span class=n>DirectoryPath</span><span class=p>,</span>
    <span class=n>skip_empty</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>  <span class=c1># (1)</span>
<span class=p>):</span>
    <span class=k>def</span> <span class=nf>generator</span><span class=p>(</span><span class=n>nlp</span><span class=p>):</span>
        <span class=c1># Read the data from the brat directory and convert it into Docs,</span>
        <span class=n>docs</span> <span class=o>=</span> <span class=n>edsnlp</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>read_standoff</span><span class=p>(</span>
            <span class=n>path</span><span class=p>,</span>
            <span class=c1># Store spans in default &quot;ents&quot;, and &quot;ml-ner&quot; for the training (prev. section)</span>
            <span class=n>span_setter</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;ents&quot;</span><span class=p>,</span> <span class=s2>&quot;ml-ner&quot;</span><span class=p>],</span>
            <span class=c1># Tokenize the training docs with the same tokenizer as the trained model</span>
            <span class=n>tokenizer</span><span class=o>=</span><span class=n>nlp</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>,</span>
        <span class=p>)</span>
        <span class=k>for</span> <span class=n>doc</span> <span class=ow>in</span> <span class=n>docs</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>skip_empty</span> <span class=ow>and</span> <span class=nb>len</span><span class=p>(</span><span class=n>doc</span><span class=o>.</span><span class=n>ents</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
                <span class=k>continue</span>
            <span class=k>yield</span> <span class=n>doc</span>

    <span class=k>return</span> <span class=n>generator</span>
</code></pre></div> <ol> <li>We can skip documents that do not contain any annotations. However, this parameter should be false when loading documents used to evaluate the pipeline.</li> </ol> <h3 id=3-loading-the-data>3. Loading the data</h3> <p>We then load and adapt (i.e., convert into spaCy Doc objects) the training and validation dataset. Since the adaption of raw documents depends on tokenization used in the trained model, we need to pass the model to the adapter function.</p> <div class="no-check highlight"><pre><span></span><code><span class=n>train_adapter</span> <span class=o>=</span> <span class=n>ner_adapter</span><span class=p>(</span><span class=n>train_data_path</span><span class=p>)</span>
<span class=n>val_adapter</span> <span class=o>=</span> <span class=n>ner_adapter</span><span class=p>(</span><span class=n>val_data_path</span><span class=p>)</span>

<span class=n>train_docs</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>train_adapter</span><span class=p>(</span><span class=n>nlp</span><span class=p>))</span>
<span class=n>val_docs</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>val_adapter</span><span class=p>(</span><span class=n>nlp</span><span class=p>))</span>
</code></pre></div> <h3 id=4-complete-the-initialization-with-the-training-data>4. Complete the initialization with the training data</h3> <p>We initialize the missing or incomplete components attributes (such as label vocabularies) with the training dataset</p> <div class="no-check highlight"><pre><span></span><code><span class=n>nlp</span><span class=o>.</span><span class=n>post_init</span><span class=p>(</span><span class=n>train_docs</span><span class=p>)</span>
</code></pre></div> <h3 id=5-preprocessing-the-data>5. Preprocessing the data</h3> <p>The training dataset is then preprocessed into features. The resulting preprocessed dataset is then wrapped into a pytorch DataLoader to be fed to the model during the training loop with the model's own collate method.</p> <div class="no-check highlight"><pre><span></span><code><span class=kn>import</span> <span class=nn>torch</span>

<span class=n>batch_size</span> <span class=o>=</span> <span class=mi>8</span>

<span class=n>preprocessed</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span>
    <span class=n>nlp</span><span class=o>.</span><span class=n>preprocess_many</span><span class=p>(</span>  <span class=c1># (1)</span>
       <span class=n>train_docs</span><span class=p>,</span>
       <span class=n>supervision</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=p>)</span>
<span class=p>)</span>
<span class=n>dataloader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span>
    <span class=n>preprocessed</span><span class=p>,</span>
    <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span>
    <span class=n>collate_fn</span><span class=o>=</span><span class=n>nlp</span><span class=o>.</span><span class=n>collate</span><span class=p>,</span>
    <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
<span class=p>)</span>
</code></pre></div> <ol> <li>This will call the <code>preprocess_supervised</code> method of the <a class="autorefs autorefs-internal" href="../../concepts/torch-component/#edsnlp.core.torch_component.TorchComponent">TorchComponent</a> class on every document and return a list of dictionaries containing the features and labels of each document.</li> </ol> <h3 id=6-looping-through-the-training-data>6. Looping through the training data</h3> <p>We instantiate an optimizer and start the training loop</p> <div class="no-check highlight"><pre><span></span><code><span class=kn>from</span> <span class=nn>itertools</span> <span class=kn>import</span> <span class=n>chain</span><span class=p>,</span> <span class=n>repeat</span>
<span class=kn>from</span> <span class=nn>tqdm</span> <span class=kn>import</span> <span class=n>tqdm</span>

<span class=n>lr</span> <span class=o>=</span> <span class=mf>3e-4</span>
<span class=n>max_steps</span> <span class=o>=</span> <span class=mi>400</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>(</span>
    <span class=n>params</span><span class=o>=</span><span class=n>nlp</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span>
    <span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>,</span>
<span class=p>)</span>

<span class=c1># We will loop over the dataloader</span>
<span class=n>iterator</span> <span class=o>=</span> <span class=n>chain</span><span class=o>.</span><span class=n>from_iterable</span><span class=p>(</span><span class=n>repeat</span><span class=p>(</span><span class=n>dataloader</span><span class=p>))</span>

<span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>max_steps</span><span class=p>),</span> <span class=s2>&quot;Training model&quot;</span><span class=p>,</span> <span class=n>leave</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
    <span class=n>batch</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=n>iterator</span><span class=p>)</span>
    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</code></pre></div> <h3 id=7-optimizing-the-weights>7. Optimizing the weights</h3> <p>Inside the training loop, the trainable components are fed the collated batches from the dataloader by calling the <a class="autorefs autorefs-internal" href="../../reference/edsnlp/core/torch_component/#edsnlp.core.torch_component.TorchComponent.module_forward"><code>TorchComponent.module_forward</code></a> methods to compute the losses. In the case we train a multi-task model (not in this tutorial), the outputs of shared embedding are reused between components, we enable caching by wrapping this step in a cache context. The training loop is otherwise carried in a similar fashion to a standard pytorch training loop</p> <div class="no-check highlight"><pre><span></span><code>    <span class=k>with</span> <span class=n>nlp</span><span class=o>.</span><span class=n>cache</span><span class=p>():</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((),</span> <span class=n>device</span><span class=o>=</span><span class=s2>&quot;cpu&quot;</span><span class=p>)</span>
        <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>component</span> <span class=ow>in</span> <span class=n>nlp</span><span class=o>.</span><span class=n>torch_components</span><span class=p>():</span>
            <span class=n>output</span> <span class=o>=</span> <span class=n>component</span><span class=o>.</span><span class=n>module_forward</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=n>component</span><span class=o>.</span><span class=n>name</span><span class=p>])</span>  <span class=c1># (1)</span>
            <span class=k>if</span> <span class=s2>&quot;loss&quot;</span> <span class=ow>in</span> <span class=n>output</span><span class=p>:</span>
                <span class=n>loss</span> <span class=o>+=</span> <span class=n>output</span><span class=p>[</span><span class=s2>&quot;loss&quot;</span><span class=p>]</span>

    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</code></pre></div> <ol> <li>We use the <code>module_forward</code> instead of a standard call, since the <code>__call__</code> method of EDS-NLP components is used to run a component on a spaCy Doc.</li> </ol> <h3 id=8-evaluating-the-model>8. Evaluating the model</h3> <p>Finally, the model is evaluated on the validation dataset and saved at regular intervals.</p> <div class="no-check highlight"><pre><span></span><code><span class=kn>from</span> <span class=nn>edsnlp.scorers.ner</span> <span class=kn>import</span> <span class=n>create_ner_exact_scorer</span>
<span class=kn>from</span> <span class=nn>copy</span> <span class=kn>import</span> <span class=n>deepcopy</span>

<span class=n>scorer</span> <span class=o>=</span> <span class=n>create_ner_exact_scorer</span><span class=p>(</span><span class=n>nlp</span><span class=o>.</span><span class=n>get_pipe</span><span class=p>(</span><span class=s1>&#39;ner&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>target_span_getter</span><span class=p>)</span>

    <span class=o>...</span>

    <span class=k>if</span> <span class=p>(</span><span class=n>step</span> <span class=o>%</span> <span class=mi>100</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
        <span class=k>with</span> <span class=n>nlp</span><span class=o>.</span><span class=n>select_pipes</span><span class=p>(</span><span class=n>enable</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;ner&quot;</span><span class=p>]):</span>  <span class=c1># (1)</span>
            <span class=nb>print</span><span class=p>(</span><span class=n>scorer</span><span class=p>(</span><span class=n>val_docs</span><span class=p>,</span> <span class=n>nlp</span><span class=o>.</span><span class=n>pipe</span><span class=p>(</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>val_docs</span><span class=p>))))</span>  <span class=c1># (2)</span>

    <span class=n>nlp</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>&quot;model&quot;</span><span class=p>)</span>  <span class=c1># (3)</span>
</code></pre></div> <ol> <li>In the case we have multiple pipes in our model, we may want to selectively evaluate each pipe, thus we use the <code>select_pipes</code> method to disable every pipe except "ner".</li> <li>We use the <code>pipe</code> method to run the "ner" component on the validation dataset. This method is similar to the <code>__call__</code> method of EDS-NLP components, but it is used to run a component on a list of spaCy Docs.</li> <li>We could also have saved the model with <code>torch.save(model, "model.pt")</code>, but <code>nlp.save</code> avoids pickling and allows to inspect the model's files by saving them into a structured directory.</li> </ol> <h2 id=full-example>Full example</h2> <p>Let's wrap the training code in a function, and make it callable from the command line using <a href="https://github.com/aphp/confit">confit</a> !</p> <details class=example> <summary>train.py</summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>  1</span>
<span class=normal>  2</span>
<span class=normal>  3</span>
<span class=normal>  4</span>
<span class=normal>  5</span>
<span class=normal>  6</span>
<span class=normal>  7</span>
<span class=normal>  8</span>
<span class=normal>  9</span>
<span class=normal> 10</span>
<span class=normal> 11</span>
<span class=normal> 12</span>
<span class=normal> 13</span>
<span class=normal> 14</span>
<span class=normal> 15</span>
<span class=normal> 16</span>
<span class=normal> 17</span>
<span class=normal> 18</span>
<span class=normal> 19</span>
<span class=normal> 20</span>
<span class=normal> 21</span>
<span class=normal> 22</span>
<span class=normal> 23</span>
<span class=normal> 24</span>
<span class=normal> 25</span>
<span class=normal> 26</span>
<span class=normal> 27</span>
<span class=normal> 28</span>
<span class=normal> 29</span>
<span class=normal> 30</span>
<span class=normal> 31</span>
<span class=normal> 32</span>
<span class=normal> 33</span>
<span class=normal> 34</span>
<span class=normal> 35</span>
<span class=normal> 36</span>
<span class=normal> 37</span>
<span class=normal> 38</span>
<span class=normal> 39</span>
<span class=normal> 40</span>
<span class=normal> 41</span>
<span class=normal> 42</span>
<span class=normal> 43</span>
<span class=normal> 44</span>
<span class=normal> 45</span>
<span class=normal> 46</span>
<span class=normal> 47</span>
<span class=normal> 48</span>
<span class=normal> 49</span>
<span class=normal> 50</span>
<span class=normal> 51</span>
<span class=normal> 52</span>
<span class=normal> 53</span>
<span class=normal> 54</span>
<span class=normal> 55</span>
<span class=normal> 56</span>
<span class=normal> 57</span>
<span class=normal> 58</span>
<span class=normal> 59</span>
<span class=normal> 60</span>
<span class=normal> 61</span>
<span class=normal> 62</span>
<span class=normal> 63</span>
<span class=normal> 64</span>
<span class=normal> 65</span>
<span class=normal> 66</span>
<span class=normal> 67</span>
<span class=normal> 68</span>
<span class=normal> 69</span>
<span class=normal> 70</span>
<span class=normal> 71</span>
<span class=normal> 72</span>
<span class=normal> 73</span>
<span class=normal> 74</span>
<span class=normal> 75</span>
<span class=normal> 76</span>
<span class=normal> 77</span>
<span class=normal> 78</span>
<span class=normal> 79</span>
<span class=normal> 80</span>
<span class=normal> 81</span>
<span class=normal> 82</span>
<span class=normal> 83</span>
<span class=normal> 84</span>
<span class=normal> 85</span>
<span class=normal> 86</span>
<span class=normal> 87</span>
<span class=normal> 88</span>
<span class=normal> 89</span>
<span class=normal> 90</span>
<span class=normal> 91</span>
<span class=normal> 92</span>
<span class=normal> 93</span>
<span class=normal> 94</span>
<span class=normal> 95</span>
<span class=normal> 96</span>
<span class=normal> 97</span>
<span class=normal> 98</span>
<span class=normal> 99</span>
<span class=normal>100</span>
<span class=normal>101</span>
<span class=normal>102</span>
<span class=normal>103</span>
<span class=normal>104</span>
<span class=normal>105</span>
<span class=normal>106</span>
<span class=normal>107</span>
<span class=normal>108</span>
<span class=normal>109</span>
<span class=normal>110</span>
<span class=normal>111</span>
<span class=normal>112</span>
<span class=normal>113</span>
<span class=normal>114</span>
<span class=normal>115</span>
<span class=normal>116</span>
<span class=normal>117</span>
<span class=normal>118</span>
<span class=normal>119</span>
<span class=normal>120</span>
<span class=normal>121</span>
<span class=normal>122</span>
<span class=normal>123</span>
<span class=normal>124</span>
<span class=normal>125</span>
<span class=normal>126</span>
<span class=normal>127</span>
<span class=normal>128</span>
<span class=normal>129</span>
<span class=normal>130</span>
<span class=normal>131</span>
<span class=normal>132</span>
<span class=normal>133</span>
<span class=normal>134</span>
<span class=normal>135</span></pre></div></td><td class=code><div><pre><span></span><code><span class=kn>from</span> <span class=nn>copy</span> <span class=kn>import</span> <span class=n>deepcopy</span>
<span class=kn>from</span> <span class=nn>itertools</span> <span class=kn>import</span> <span class=n>chain</span><span class=p>,</span> <span class=n>repeat</span>
<span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Callable</span><span class=p>,</span> <span class=n>Iterable</span>

<span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>from</span> <span class=nn>confit</span> <span class=kn>import</span> <span class=n>Cli</span>
<span class=kn>from</span> <span class=nn>pydantic</span> <span class=kn>import</span> <span class=n>DirectoryPath</span>
<span class=kn>from</span> <span class=nn>spacy.tokens</span> <span class=kn>import</span> <span class=n>Doc</span>
<span class=kn>from</span> <span class=nn>tqdm</span> <span class=kn>import</span> <span class=n>tqdm</span>

<span class=kn>import</span> <span class=nn>edsnlp</span>
<span class=kn>from</span> <span class=nn>edsnlp</span> <span class=kn>import</span> <span class=n>registry</span><span class=p>,</span> <span class=n>Pipeline</span>
<span class=kn>from</span> <span class=nn>edsnlp.scorers.ner</span> <span class=kn>import</span> <span class=n>create_ner_exact_scorer</span>


<span class=nd>@registry</span><span class=o>.</span><span class=n>adapters</span><span class=o>.</span><span class=n>register</span><span class=p>(</span><span class=s2>&quot;ner_adapter&quot;</span><span class=p>)</span>
<span class=k>def</span> <span class=nf>ner_adapter</span><span class=p>(</span>
    <span class=n>path</span><span class=p>:</span> <span class=n>DirectoryPath</span><span class=p>,</span>
    <span class=n>skip_empty</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<span class=p>):</span>
    <span class=k>def</span> <span class=nf>generator</span><span class=p>(</span><span class=n>nlp</span><span class=p>):</span>
        <span class=c1># Read the data from the brat directory and convert it into Docs,</span>
        <span class=n>docs</span> <span class=o>=</span> <span class=n>edsnlp</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>read_standoff</span><span class=p>(</span>
           <span class=n>path</span><span class=p>,</span>
           <span class=c1># Store spans in default &quot;ents&quot;, and &quot;ml-ner&quot; for the training</span>
           <span class=n>span_setter</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;ents&quot;</span><span class=p>,</span> <span class=s2>&quot;ml-ner&quot;</span><span class=p>],</span>
           <span class=c1># Tokenize the training docs with the same tokenizer as the trained model</span>
           <span class=n>tokenizer</span><span class=o>=</span><span class=n>nlp</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>,</span>
        <span class=p>)</span>
        <span class=k>for</span> <span class=n>doc</span> <span class=ow>in</span> <span class=n>docs</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>skip_empty</span> <span class=ow>and</span> <span class=nb>len</span><span class=p>(</span><span class=n>doc</span><span class=o>.</span><span class=n>ents</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
                <span class=k>continue</span>
            <span class=n>doc</span><span class=o>.</span><span class=n>spans</span><span class=p>[</span><span class=s2>&quot;ml-ner&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>doc</span><span class=o>.</span><span class=n>ents</span>
            <span class=k>yield</span> <span class=n>doc</span>

    <span class=k>return</span> <span class=n>generator</span>


<span class=n>app</span> <span class=o>=</span> <span class=n>Cli</span><span class=p>(</span><span class=n>pretty_exceptions_show_locals</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>


<span class=nd>@app</span><span class=o>.</span><span class=n>command</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s2>&quot;train&quot;</span><span class=p>,</span> <span class=n>registry</span><span class=o>=</span><span class=n>registry</span><span class=p>)</span>  <span class=c1># (1)</span>
<span class=k>def</span> <span class=nf>train</span><span class=p>(</span>
    <span class=n>nlp</span><span class=p>:</span> <span class=n>Pipeline</span><span class=p>,</span>
    <span class=n>train_adapter</span><span class=p>:</span> <span class=n>Callable</span><span class=p>[[</span><span class=n>Pipeline</span><span class=p>],</span> <span class=n>Iterable</span><span class=p>[</span><span class=n>Doc</span><span class=p>]],</span>
    <span class=n>val_adapter</span><span class=p>:</span> <span class=n>Callable</span><span class=p>[[</span><span class=n>Pipeline</span><span class=p>],</span> <span class=n>Iterable</span><span class=p>[</span><span class=n>Doc</span><span class=p>]],</span>
    <span class=n>max_steps</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1000</span><span class=p>,</span>
    <span class=n>seed</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>42</span><span class=p>,</span>
    <span class=n>lr</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>3e-4</span><span class=p>,</span>
    <span class=n>batch_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>4</span><span class=p>,</span>
<span class=p>):</span>
    <span class=c1># Adapting a dataset</span>
    <span class=n>train_docs</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>train_adapter</span><span class=p>(</span><span class=n>nlp</span><span class=p>))</span>
    <span class=n>val_docs</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>val_adapter</span><span class=p>(</span><span class=n>nlp</span><span class=p>))</span>

    <span class=c1># Complete the initialization with the training data</span>
    <span class=n>nlp</span><span class=o>.</span><span class=n>post_init</span><span class=p>(</span><span class=n>train_docs</span><span class=p>)</span>

    <span class=c1># Preprocessing the data</span>
    <span class=n>preprocessed</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span>
        <span class=n>nlp</span><span class=o>.</span><span class=n>preprocess_many</span><span class=p>(</span>
            <span class=n>train_docs</span><span class=p>,</span>
            <span class=n>supervision</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
        <span class=p>)</span>
    <span class=p>)</span>
    <span class=n>dataloader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span>
        <span class=n>preprocessed</span><span class=p>,</span>
        <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span>
        <span class=n>collate_fn</span><span class=o>=</span><span class=n>nlp</span><span class=o>.</span><span class=n>collate</span><span class=p>,</span>
        <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=p>)</span>

    <span class=n>scorer</span> <span class=o>=</span> <span class=n>create_ner_exact_scorer</span><span class=p>(</span><span class=n>nlp</span><span class=o>.</span><span class=n>get_pipe</span><span class=p>(</span><span class=s2>&quot;ner&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>target_span_getter</span><span class=p>)</span>

    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>(</span>
        <span class=n>params</span><span class=o>=</span><span class=n>nlp</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span>
        <span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>,</span>
    <span class=p>)</span>

    <span class=n>iterator</span> <span class=o>=</span> <span class=n>chain</span><span class=o>.</span><span class=n>from_iterable</span><span class=p>(</span><span class=n>repeat</span><span class=p>(</span><span class=n>dataloader</span><span class=p>))</span>

    <span class=c1># Looping through the training data</span>
    <span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>max_steps</span><span class=p>),</span> <span class=s2>&quot;Training model&quot;</span><span class=p>,</span> <span class=n>leave</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
        <span class=n>batch</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=n>iterator</span><span class=p>)</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=n>loss</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((),</span> <span class=n>device</span><span class=o>=</span><span class=s2>&quot;cpu&quot;</span><span class=p>)</span>
        <span class=k>with</span> <span class=n>nlp</span><span class=o>.</span><span class=n>cache</span><span class=p>():</span>
            <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>component</span> <span class=ow>in</span> <span class=n>nlp</span><span class=o>.</span><span class=n>torch_components</span><span class=p>():</span>
                <span class=n>output</span> <span class=o>=</span> <span class=n>component</span><span class=o>.</span><span class=n>module_forward</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=n>component</span><span class=o>.</span><span class=n>name</span><span class=p>])</span>
                <span class=k>if</span> <span class=s2>&quot;loss&quot;</span> <span class=ow>in</span> <span class=n>output</span><span class=p>:</span>
                    <span class=n>loss</span> <span class=o>+=</span> <span class=n>output</span><span class=p>[</span><span class=s2>&quot;loss&quot;</span><span class=p>]</span>

        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=c1># Evaluating the model</span>
        <span class=k>if</span> <span class=p>(</span><span class=n>step</span> <span class=o>%</span> <span class=mi>100</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=k>with</span> <span class=n>nlp</span><span class=o>.</span><span class=n>select_pipes</span><span class=p>(</span><span class=n>enable</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;ner&quot;</span><span class=p>]):</span>  <span class=c1>#</span>
                <span class=nb>print</span><span class=p>(</span><span class=n>scorer</span><span class=p>(</span><span class=n>val_docs</span><span class=p>,</span> <span class=n>nlp</span><span class=o>.</span><span class=n>pipe</span><span class=p>(</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>val_docs</span><span class=p>))))</span>  <span class=c1>#</span>

        <span class=n>nlp</span><span class=o>.</span><span class=n>to_disk</span><span class=p>(</span><span class=s2>&quot;model&quot;</span><span class=p>)</span>


<span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&quot;__main__&quot;</span><span class=p>:</span>
    <span class=n>nlp</span> <span class=o>=</span> <span class=n>edsnlp</span><span class=o>.</span><span class=n>blank</span><span class=p>(</span><span class=s2>&quot;eds&quot;</span><span class=p>)</span>
    <span class=n>nlp</span><span class=o>.</span><span class=n>add_pipe</span><span class=p>(</span>
        <span class=s2>&quot;<a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a>&quot;</span><span class=p>,</span>
        <span class=n>name</span><span class=o>=</span><span class=s2>&quot;ner&quot;</span><span class=p>,</span>
        <span class=n>config</span><span class=o>=</span><span class=p>{</span>
            <span class=s2>&quot;mode&quot;</span><span class=p>:</span> <span class=s2>&quot;joint&quot;</span><span class=p>,</span>
            <span class=s2>&quot;target_span_getter&quot;</span><span class=p>:</span> <span class=s2>&quot;ml-ner&quot;</span><span class=p>,</span>
            <span class=s2>&quot;window&quot;</span><span class=p>:</span> <span class=mi>20</span><span class=p>,</span>
            <span class=s2>&quot;embedding&quot;</span><span class=p>:</span> <span class=p>{</span>
                <span class=s2>&quot;@factory&quot;</span><span class=p>:</span> <span class=s2>&quot;<a href="../../pipes/trainable/embeddings/text_cnn/#edsnlp.pipes.trainable.embeddings.text_cnn.factory.create_component">eds.text_cnn</a>&quot;</span><span class=p>,</span>
                <span class=s2>&quot;kernel_sizes&quot;</span><span class=p>:</span> <span class=p>[</span><span class=mi>3</span><span class=p>],</span>
                <span class=s2>&quot;embedding&quot;</span><span class=p>:</span> <span class=p>{</span>
                    <span class=s2>&quot;@factory&quot;</span><span class=p>:</span> <span class=s2>&quot;<a href="../../pipes/trainable/embeddings/transformer/#edsnlp.pipes.trainable.embeddings.transformer.factory.create_component">eds.transformer</a>&quot;</span><span class=p>,</span>
                    <span class=s2>&quot;model&quot;</span><span class=p>:</span> <span class=s2>&quot;prajjwal1/bert-tiny&quot;</span><span class=p>,</span>
                    <span class=s2>&quot;window&quot;</span><span class=p>:</span> <span class=mi>128</span><span class=p>,</span>
                    <span class=s2>&quot;stride&quot;</span><span class=p>:</span> <span class=mi>96</span><span class=p>,</span>
                <span class=p>},</span>
            <span class=p>},</span>
        <span class=p>},</span>
    <span class=p>)</span>
    <span class=n>train</span><span class=p>(</span>
        <span class=n>nlp</span><span class=o>=</span><span class=n>nlp</span><span class=p>,</span>
        <span class=n>train_adapter</span><span class=o>=</span><span class=n>ner_adapter</span><span class=p>(</span><span class=s2>&quot;data/train&quot;</span><span class=p>),</span>
        <span class=n>val_adapter</span><span class=o>=</span><span class=n>ner_adapter</span><span class=p>(</span><span class=s2>&quot;data/val&quot;</span><span class=p>),</span>
        <span class=n>max_steps</span><span class=o>=</span><span class=mi>400</span><span class=p>,</span>
        <span class=n>seed</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span>
        <span class=n>lr</span><span class=o>=</span><span class=mf>3e-4</span><span class=p>,</span>
        <span class=n>batch_size</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
    <span class=p>)</span>
</code></pre></div></td></tr></table></div> <ol> <li>This will become useful in the next section, when we will use the configuration file to define the pipeline. If you don't want to use a configuration file, you can remove this decorator.</li> </ol> </details> <p>We can now copy the above code in a notebook and run it, or call this script from the command line:</p> <div class=highlight data-md-color-scheme=slate><pre><span></span><code>python train.py --seed 42
</code></pre></div> <p>At the end of the training, the pipeline is ready to use (with the <code>.pipe</code> method) since every trained component of the pipeline is self-sufficient, ie contains the preprocessing, inference and postprocessing code required to run it.</p> <h2 id=configuration>Configuration</h2> <p>To decouple the configuration and the code of our training script, let's define a configuration file where we will describe <strong>both</strong> our training parameters and the pipeline. You can either write the config of the pipeline by hand, or generate a pipeline config draft from an instantiated pipeline by running:</p> <div class="no-check highlight"><pre><span></span><code><span class=nb>print</span><span class=p>(</span><span class=n>nlp</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>to_str</span><span class=p>())</span>
</code></pre></div> <div class=highlight><span class=filename>config.cfg</span><pre><span></span><code><span class=c1># This is this equivalent of the API-based declaration</span>
<span class=c1># at the beginning of the tutorial</span>
<span class=k>[nlp]</span>
<span class=n>lang</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s2>&quot;eds&quot;</span>
<span class=n>pipeline</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>[</span><span class=s2>&quot;ner&quot;</span><span class=p>]</span>
<span class=n>components</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=err>$</span><span class=p>{</span><span class=w> </span><span class=n>components</span><span class=w> </span><span class=p>}</span>

<span class=k>[components]</span>

<span class=k>[components.ner]</span>
<span class=err>@</span><span class=n>factory</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s2>&quot;<a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a>&quot;</span>
<span class=n>mode</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s2>&quot;joint&quot;</span>
<span class=n>target_span_getter</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s2>&quot;ml-ner&quot;</span>
<span class=n>window</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>20</span>
<span class=n>embedding</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=err>$</span><span class=p>{</span><span class=w> </span><span class=n>cnn</span><span class=w> </span><span class=p>}</span>

<span class=k>[cnn]</span>
<span class=err>@</span><span class=n>factory</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s2>&quot;<a href="../../pipes/trainable/embeddings/text_cnn/#edsnlp.pipes.trainable.embeddings.text_cnn.factory.create_component">eds.text_cnn</a>&quot;</span>
<span class=n>kernel_sizes</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>[</span><span class=mi>3</span><span class=p>]</span>
<span class=n>embedding</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=err>$</span><span class=p>{</span><span class=w> </span><span class=n>transformer</span><span class=w> </span><span class=p>}</span>

<span class=k>[transformer]</span>
<span class=err>@</span><span class=n>factory</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s2>&quot;<a href="../../pipes/trainable/embeddings/transformer/#edsnlp.pipes.trainable.embeddings.transformer.factory.create_component">eds.transformer</a>&quot;</span>
<span class=n>model</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s2>&quot;prajjwal1/bert-tiny&quot;</span>
<span class=n>window</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>128</span>
<span class=n>stride</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=err>$</span><span class=p>{</span><span class=w> </span><span class=n>transformer</span><span class=p>.</span><span class=n>window</span><span class=err>//</span><span class=n>2</span><span class=w> </span><span class=p>}</span>

<span class=c1># This is were we define the training script parameters</span>
<span class=c1># the &quot;train&quot; section refers to the name of the command</span>
<span class=c1># in the training script</span>
<span class=k>[train]</span>
<span class=n>nlp</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=err>$</span><span class=p>{</span><span class=w> </span><span class=n>nlp</span><span class=w> </span><span class=p>}</span>
<span class=n>train_adapter</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>{</span><span class=w> </span><span class=s2>&quot;@adapters&quot;</span><span class=err>:</span><span class=w> </span><span class=s2>&quot;ner_adapter&quot;</span><span class=p>,</span><span class=w> </span><span class=s2>&quot;path&quot;</span><span class=err>:</span><span class=w> </span><span class=s2>&quot;data/train&quot;</span><span class=w> </span><span class=p>}</span>
<span class=n>val_adapter</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>{</span><span class=w> </span><span class=s2>&quot;@adapters&quot;</span><span class=err>:</span><span class=w> </span><span class=s2>&quot;ner_adapter&quot;</span><span class=p>,</span><span class=w> </span><span class=s2>&quot;path&quot;</span><span class=err>:</span><span class=w> </span><span class=s2>&quot;data/val&quot;</span><span class=w> </span><span class=p>}</span>
<span class=n>max_steps</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>400</span>
<span class=n>seed</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>42</span>
<span class=n>lr</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mf>3e-4</span>
<span class=n>batch_size</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>8</span>
</code></pre></div> <p>And replace the end of the script by</p> <div class="no-check highlight"><pre><span></span><code><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&quot;__main__&quot;</span><span class=p>:</span>
    <span class=n>app</span><span class=o>.</span><span class=n>run</span><span class=p>()</span>
</code></pre></div> <p>That's it ! We can now call the training script with the configuration file as a parameter, and override some of its values:</p> <div class=highlight data-md-color-scheme=slate><pre><span></span><code>python<span class=w> </span>train.py<span class=w> </span>--config<span class=w> </span>config.cfg<span class=w> </span>--transformer.window<span class=o>=</span><span class=m>64</span><span class=w> </span>--seed<span class=w> </span><span class=m>43</span>
</code></pre></div> <h2 id=going-further>Going further</h2> <p>This tutorial gave you a glimpse of the training API of EDS-NLP. We provide a more complete example of a training script in tests at <a href="https://github.com/aphp/edsnlp/blob/master/tests/training/test_training.py">tests/training/test_training.py</a>. To build a custom trainable component, you can refer to the <a class="autorefs autorefs-internal" href="../../concepts/torch-component/#edsnlp.core.torch_component.TorchComponent">TorchComponent</a> class or look up the implementation of some of the trainable components on GitHub.</p> <div class=footnote><hr><ol/></div> </article> </div> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href="../../advanced-tutorials/fastapi/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Deploying as an API" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Deploying as an API </div> </div> </a> <a href="../quick-examples/" class="md-footer__link md-footer__link--next" aria-label="Next: Display single text outputs" rel=next> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Display single text outputs </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href="https://squidfunk.github.io/mkdocs-material/" target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["navigation.tracking", "navigation.instant", "navigation.indexes", "navigation.prune", "navigation.top", "navigation.footer", "content.code.annotate", "content.code.copy"], "search": "../../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script> <script src=../../assets/javascripts/bundle.dff1b7c8.min.js></script> <script src=https://cdn.jsdelivr.net/npm/vega@5></script> <script src=https://cdn.jsdelivr.net/npm/vega-lite@5></script> <script src=https://cdn.jsdelivr.net/npm/vega-embed@6></script> <script src=../../assets/termynal/termynal.js></script> </body> </html>